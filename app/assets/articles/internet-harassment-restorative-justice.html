<p class="css-exrw3m evys1bk0">As we all spend our days yelling at one another online, it’s easy to despair and wonder: Is there any way to fix our toxic internet?</p><p class="css-exrw3m evys1bk0">Micah Loewinger, a producer for WNYC’s “On the Media,” <a class="css-1g7m0tk" href="https://www.wnycstudios.org/story/on-the-media-fix-the-internet" rel="noopener noreferrer" target="_blank" title="">was pondering this question</a> when he met Lindsay Blackwell, a Ph.D. student at the University of Michigan who studies online harassment. Ms. Blackwell, also a researcher at Facebook, had been toying with the idea of applying the principles of the restorative justice movement to online content moderation (you can <a class="css-1g7m0tk" href="https://www.wnycstudios.org/story/on-the-media-fix-the-internet" rel="noopener noreferrer" target="_blank" title="">listen to their episode here</a>). </p><p class="css-exrw3m evys1bk0">Restorative justice is an alternative form of criminal justice that focuses on mediation. Often, an offender will meet with the victim and the broader community with a chance to make amends. The confrontation, advocates of the technique argue, helps the offender come to terms with the crime while giving the victim a chance to be heard. If the relationship is repaired and the harm to the victim reduced, the offender is allowed to re-enter the community. Studies, including one by the <a class="css-1g7m0tk" href="https://www.ncjrs.gov/pdffiles1/ojjdp/grants/250995.pdf" rel="noopener noreferrer" target="_blank" title="">Department of Justice</a>, suggest the approach can be an effective way to decrease repeat offenses and <a class="css-1g7m0tk" href="https://www.seattletimes.com/opinion/restorative-justice-works-for-perpetrators-and-victims/" rel="noopener noreferrer" target="_blank" title="">works for perpetrators and victims</a>. </p><p class="css-exrw3m evys1bk0"><em class="css-2fg4z9 e1gzwzxm0">[As technology advances, will it continue to blur the lines between public and private? </em><a class="css-1g7m0tk" href="https://www.nytimes.com/newsletters/privacy-project?action=click&amp;module=inline&amp;pgtype=Article" title=""><em class="css-2fg4z9 e1gzwzxm0">Sign up for Charlie Warzel’s limited-run newsletter</em></a><em class="css-2fg4z9 e1gzwzxm0"> to explore what’s at stake and what you can do about it.]</em></p><p class="css-exrw3m evys1bk0">For Ms. Blackwell, applying a similar tactic to tech platforms made sense. Current tech company enforcements, if enacted, tend to be harsh and geared toward deterrence, not treating the underlying causes of rule-breaking behavior. </p><p class="css-exrw3m evys1bk0">Ms. Blackwell and Mr. Loewinger decided to run what they called “a highly unscientific” experiment on Reddit, a social network with tens of thousands of forum communities. Each community is policed by volunteer moderators who take down offensive posts and enforce that community’s set of rules. Ms. Blackwell and Mr. Loewinger teamed up with the moderators of Reddit’s r/Christianity community, which has roughly <!-- -->200,000 members<!-- -->. It is diverse, comprising L.G.B.T.Q. Christians, fundamentalists, <!-- -->atheists<!-- --> and others with an interest in posting about the faith. Discussions get intense.</p><p class="css-exrw3m evys1bk0">The pair selected three users who were barred for repeatedly violating rules. They created a chat room where the offender and community moderator would <!-- -->meet <!-- -->with Mr. Loewinger and Ms. Blackwell, who acted as mediators. The offenders would be confronted with past bad behavior and given the opportunity to better understand why they were barred. Upon successful completion, they’d be readmitted to the group. </p><p class="css-exrw3m evys1bk0">The results were mixed. In one case, mediation broke down, in part because of Ms. Blackwell and Mr. Loewinger’s inexperience <!-- -->mediating <!-- -->and tensions <!-- -->between a user and a moderator <!-- -->that boiled over. The second case, which involved an anti-gay user who was accused of bullying an L.G.B.T.Q. user into committing suicide years ago, proved simply too toxic to continue. The third case, involving “James,” an atheist and biblical historian who was barred for repeatedly violating r/Christianity’s rules for civil discussion, was a success. </p><p class="css-exrw3m evys1bk0">At various points throughout the chat log of the mediation, James expressed genuine shock. “Dang this wasn’t the context that I remembered,” he types at one point, after looking at past bullying posts. “I thought someone else was the instigator and I felt ganged-up on or something. But … looks like I was the instigator.” He apologized for lashing out, at one point suggesting “the problem is more obviously about (mis) communication and hostility that comes up in the course of these conversations.” Eventually, the moderators lifted their ban. </p><p class="css-exrw3m evys1bk0">When I spoke to James over the phone about the process, he described his aggressive behavior as a kind of dissociation — a moment of weakness where he stopped seeing those on the other end of the thread as real people. “My frustration expressed itself as insult diarrhea with no regard to whether I was being reasonable,” he said. He noted that he’d been back in the community for two months, is more conscious of his interactions and has yet to break the rules. </p><p class="css-exrw3m evys1bk0">James isn’t convinced the process could work for everyone. He argued that mediation was effective for his specific personality type. “It’s the element of shame,” he said. “I’m somebody who feels guilt being confronted and it allowed me to see I was the one at fault.” Ms. Blackwell and Mr. Loewinger’s mixed results suggest success is far from guaranteed. Online, mediators have to deal with pseudonymous individuals, trolls and pranksters with no desire to reform. Even those dealing in good faith might bristle at having to apologize or confront their victims. Given the nature of online harassment and bullying, the restorative justice approach is full of pitfalls. Forcing targeted minorities or vulnerable users to confront abusers, for one, could increase trauma or put undue burden on victims.</p><p class="css-exrw3m evys1bk0">Most daunting is the issue of scale. There’s simply no way to replicate the amount of time and effort involved with Ms. Blackwell and Mr. Loewinger’s experiment across the web. “It’s like trying to moderate a wild river,” an r/Christianity moderator said in the chat logs. “It’s only getting worse, too. I can’t even begin to evaluate all of this stuff.” The ceaseless torrent of posts and comments is why tech platforms are increasingly turning to algorithms and artificial intelligence to solve the problem. </p><p class="css-exrw3m evys1bk0">But successful moderation — the kind that not only keeps a community from collapsing under the weight of its own toxicity but also creates a healthy forum — requires a human touch. Even skilled moderators assume a huge psychological burden; many working for Facebook and YouTube are outside contractors, subjected daily to torrents of psychologically traumatizing content and almost always without <a class="css-1g7m0tk" href="https://www.theverge.com/2019/6/19/18681845/facebook-moderator-interviews-video-trauma-ptsd-cognizant-tampa" rel="noopener noreferrer" target="_blank" title="">proper </a><a class="css-1g7m0tk" href="https://www.theverge.com/2019/6/19/18681845/facebook-moderator-interviews-video-trauma-ptsd-cognizant-tampa" rel="noopener noreferrer" target="_blank" title="">resources</a>. Even in small communities, keeping the peace requires a herculean effort. A recent <a class="css-1g7m0tk" href="https://www.newyorker.com/news/letter-from-silicon-valley/the-lonely-work-of-moderating-hacker-news" rel="noopener noreferrer" target="_blank" title="">New Yorker article described</a> the job of two human moderators of a midsize tech-news message board as an act of “relentless patience and <!-- -->good<!-- --> faith.” </p><p class="css-exrw3m evys1bk0">This reality makes Ms. Blackwell and Mr. Loewinger’s experiment equal parts compelling and dispiriting. Mr. Loewinger remains optimistic. “It’s easy to write off all people who exhibit jerk-ish behavior online as pathological trolls,” he told me. “Dislodging that assumption might hold the key to a less toxic web. The James case demonstrated to me that people are open to reflecting on what they’ve done, especially when treated with dignity.” Ms. Blackwell argued that having reformed users back in the community actually makes the forums healthier. “We will never effectively reduce online harassment unless we address the underlying motivations for participating in abusive behavior, and having reformed violators go on to model prosocial norms is an incredible bonus,” she said.</p><p class="css-exrw3m evys1bk0">But if reform means an abundance of shame and dignity on the internet, it’s hard not to feel that all is already lost. Still, the pair’s earnestness is refreshing. And at its core there’s a lesson: If fast, scalable algorithmic solutions gave us the broken system we’ve got, it’s stripped-down patience and humanity that have the best chance of pulling us out.</p><p class="css-jwz2nf etfikam0"><em class="css-2fg4z9 e1gzwzxm0">The Times is committed to publishing </em><a class="css-1g7m0tk" href="https://www.nytimes.com/2019/01/31/opinion/letters/letters-to-editor-new-york-times-women.html" title=""><em class="css-2fg4z9 e1gzwzxm0">a diversity of letters</em></a><em class="css-2fg4z9 e1gzwzxm0"> to the editor. We’d like to hear what you think about this or any of our articles. Here are some </em><a class="css-1g7m0tk" href="https://help.nytimes.com/hc/en-us/articles/115014925288-How-to-submit-a-letter-to-the-editor" title=""><em class="css-2fg4z9 e1gzwzxm0">tips</em></a><em class="css-2fg4z9 e1gzwzxm0">. And here’s our email:</em><a class="css-1g7m0tk" href="mailto:letters@nytimes.com" title=""><em class="css-2fg4z9 e1gzwzxm0">letters@nytimes.com</em></a><em class="css-2fg4z9 e1gzwzxm0">.</em></p><p class="css-jwz2nf etfikam0"><em class="css-2fg4z9 e1gzwzxm0">Follow The New York Times Opinion section on </em><a class="css-1g7m0tk" href="https://www.facebook.com/nytopinion" rel="noopener noreferrer" target="_blank" title=""><em class="css-2fg4z9 e1gzwzxm0">Facebook</em></a><em class="css-2fg4z9 e1gzwzxm0">, </em><a class="css-1g7m0tk" href="http://twitter.com/NYTOpinion" rel="noopener noreferrer" target="_blank" title=""><em class="css-2fg4z9 e1gzwzxm0">Twitter (@NYTopinion)</em></a><em class="css-2fg4z9 e1gzwzxm0"> and </em><a class="css-1g7m0tk" href="https://www.instagram.com/nytopinion/" rel="noopener noreferrer" target="_blank" title=""><em class="css-2fg4z9 e1gzwzxm0">Instagram</em></a><em class="css-2fg4z9 e1gzwzxm0">.</em></p>