{'body': '[[<p class="css-exrw3m evys1bk0">On June 1,<!-- --> 2019, the Daily Beast <a class="css-1g7m0tk" href="https://www.thedailybeast.com/we-found-shawn-brooks-the-guy-behind-the-viral-drunk-pelosi-video" rel="noopener noreferrer" target="_blank" title="">published a story</a> exposing the creator of a now infamous fake video that appeared to show House Speaker Nancy Pelosi drunkenly slurring her words. The video was created by taking a genuine clip, slowing it down, and then adjusting the pitch of her voice to disguise the manipulation.</p>, <p class="css-exrw3m evys1bk0">Judging by <a class="css-1g7m0tk" href="https://www.nytimes.com/2019/05/26/opinion/nancy-pelosi-video-facebook.html?module=inline" title="">social media comments</a>, many people initially fell for the fake, believing that Ms. Pelosi really was drunk while speaking to the media. (If that seems an absurd thing to believe, remember <a class="css-1g7m0tk" href="https://www.nbcnews.com/tech/social-media/fire-pizzagate-shop-reignites-conspiracy-theorists-who-find-home-facebook-n965956" rel="noopener noreferrer" target="_blank" title="">Pizzagate</a>;<strong class="css-8qgvsz ebyp5n10"> </strong>people are happy to believe absurd things about politicians they don\\u2019t like.)</p>, <p class="css-exrw3m evys1bk0">The video was made by a private citizen named Shawn Brooks, who seems to have been a freelance political operative producing a wealth of pro-Trump web content. (Mr. Brooks denies creating the video, though according to the Daily Beast, Facebook confirmed he was the first to upload it.) Some commenters <a class="css-1g7m0tk" href="https://twitter.com/mtracey/status/1135176351319822338" rel="noopener noreferrer" target="_blank" title="">quickly</a> <a class="css-1g7m0tk" href="https://twitter.com/ggreenwald/status/1135030189858205696" rel="noopener noreferrer" target="_blank" title="">suggested</a><strong class="css-8qgvsz ebyp5n10"> </strong>that the Daily Beast was wrong to expose Mr. Brooks. After all, they argued, he\\u2019s only one person, not a Russian secret agent or a powerful public relations firm; and it feels like \\u201c<a class="css-1g7m0tk" href="https://twitter.com/ChuckRossDC/status/1135198139273662465" rel="noopener noreferrer" target="_blank" title="">punching down</a>\\u201d for a major news organization to turn the spotlight on one rogue amateur. Seth Mandel, an editor at the Washington Examiner, <a class="css-1g7m0tk" href="https://twitter.com/SethAMandel/status/1135024852417601537" rel="noopener noreferrer" target="_blank" title="">asked,</a> \\u201cIsn\\u2019t this like the third Daily Beast doxxing for the hell of it?\\u201d</p>, <p class="css-exrw3m evys1bk0">It\\u2019s a legitimate worry, but it misses an important point. There is good reason for journalists to expose the creators of fake web content, and it\\u2019s not just the glee of watching provocateurs squirm. We live in a time when knowing the origin of an internet video is just as important as knowing what it shows.</p>, <p class="css-exrw3m evys1bk0"><a class="css-1g7m0tk" href="https://www.nytimes.com/2019/05/24/us/politics/pelosi-doctored-video.html?module=inline" title=""><em class="css-2fg4z9 e1gzwzxm0">[Related: Distorted Videos of Nancy Pelosi Spread on Facebook and Twitter, Helped by Trump]</em></a></p>, <p class="css-exrw3m evys1bk0">Digital technology is making it much easier to fabricate convincing fakes. The video that Mr. Brooks created is pretty simple; you could probably do it yourself after watching a few YouTube clips about video editing. But more complicated fabrications, sometimes called <a class="css-1g7m0tk" href="https://www.nytimes.com/2018/03/04/technology/fake-videos-deepfakes.html?module=inline" title="">\\u201cdeepfakes,\\u201d</a> use algorithmic techniques to depict people doing things they\\u2019ve never done \\u2014 not just slowing them down or changing the pitch of their voice, but making them appear to say things that they\\u2019ve never said at all. A recent <a class="css-1g7m0tk" href="https://arxiv.org/pdf/1809.03658.pdf" rel="noopener noreferrer" target="_blank" title="">research article</a><strong class="css-8qgvsz ebyp5n10"> </strong>suggested a technique to generate full-body animations, which could effectively make digital action figures of any famous person.</p>, <p class="css-exrw3m evys1bk0">So far, this technology doesn\\u2019t seem to have been <!-- -->used in American politics<!-- -->, though it may have played some role in a political crisis in Gabon <a class="css-1g7m0tk" href="https://www.motherjones.com/politics/2019/03/deepfake-gabon-ali-bongo/" rel="noopener noreferrer" target="_blank" title="">earlier this year</a>. But it\\u2019s clear that current arguments about fake news are only a taste of what will happen when sounds and images, not just words, are open to manipulation by anyone with a decent computer.</p>, <p class="css-exrw3m evys1bk0">Combine this point with an insight from epistemology \\u2014 the branch of philosophy dealing with knowledge \\u2014 and you\\u2019ll see why the Daily Beast was right to expose the creator of the fake video of Ms. Pelosi. Contemporary philosophers rank different types of evidence according to their reliability: How much confidence, they ask, can we reasonably have in a belief when it is supported by such-and-such information?</p>, <p class="css-exrw3m evys1bk0">We ordinarily tend to think that perception \\u2014 the evidence of your eyes and ears \\u2014 provides pretty strong justification. If you see something with your own eyes, you should probably believe it. By comparison, the claims that other people make \\u2014 which philosophers call \\u201ctestimony\\u201d \\u2014 provide some justification, but usually not quite as much as perception. Sometimes, of course, your senses can deceive you, but that\\u2019s less likely than other people deceiving you.</p>, <p class="css-exrw3m evys1bk0">Until recently, video evidence functioned more or less like perception. Most of the time, you could trust that a camera captured roughly what you would have seen with your own eyes. So if you trust your own perception, you have nearly as much reason to trust the video. We all know that Hollywood studios, with enormous amounts of time and money, can use CGI to depict almost anything, but what are the odds that a random internet video came from Hollywood?</p>, <p class="css-exrw3m evys1bk0">Now, with the emergence of deepfake technology, the ability to produce convincing fake video will be almost as widespread as the ability to lie. And once that happens, we ought to think of images as <a class="css-1g7m0tk" href="https://www.cambridge.org/core/journals/episteme/article/photographically-based-knowledge/54EABE715C54782C1A55455A3E414E94" rel="noopener noreferrer" target="_blank" title="">more like testimony than perception</a>. In other words, you should only trust a recording if you would trust the word of the person producing it.</p>, <p class="css-exrw3m evys1bk0">Which means that it <em class="css-2fg4z9 e1gzwzxm0">does</em> matter where the fake Nancy Pelosi video, and others like it, come from. This time we knew the video was fake because we had access to the original. But with future deepfakes, there won\\u2019t be any original to compare them to. To know whether a disputed video is real, we\\u2019ll need to know who made it.</p>, <p class="css-exrw3m evys1bk0">It\\u2019s good for journalists to start getting in the habit of tracking down creators of mysterious web content. And it\\u2019s good for the rest of us to start expecting as much from the media. When deepfakes fully arrive, we\\u2019ll be glad we\\u2019ve prepared. For now, even if it\\u2019s not ideal to have amateur political operatives exposed to the ire of the internet, it\\u2019s better than carrying on as if we can still trust our lying videos.</p>, <p class="css-jwz2nf etfikam0">Regina Rini (<a class="css-1g7m0tk" href="https://twitter.com/rinireg" rel="noopener noreferrer" target="_blank" title="">@rinireg</a>) teaches philosophy at York University in Toronto, where she holds the Canada Research Chair in Philosophy of Moral and Social Cognition.</p>, <p class="css-jwz2nf etfikam0"><strong class="css-8qgvsz ebyp5n10"><em class="css-2fg4z9 e1gzwzxm0">Now in print</em></strong><em class="css-2fg4z9 e1gzwzxm0">: \\u201cModern Ethics in 77 Arguments\\u201d and \\u201cThe Stone Reader: Modern Philosophy in 133 Arguments,\\u201d with essays from the series, edited by Peter Catapano and Simon Critchley, published by Liveright Books.</em></p>, <p class="css-jwz2nf etfikam0"><em class="css-2fg4z9 e1gzwzxm0">The Times is committed to publishing </em><a class="css-1g7m0tk" href="https://www.nytimes.com/2019/01/31/opinion/letters/letters-to-editor-new-york-times-women.html" title=""><em class="css-2fg4z9 e1gzwzxm0">a diversity of letters</em></a><em class="css-2fg4z9 e1gzwzxm0"> to the editor. We\\u2019d like to hear what you think about this or any of our articles. Here are some </em><a class="css-1g7m0tk" href="https://help.nytimes.com/hc/en-us/articles/115014925288-How-to-submit-a-letter-to-the-editor" title=""><em class="css-2fg4z9 e1gzwzxm0">tips</em></a><em class="css-2fg4z9 e1gzwzxm0">. And here\\u2019s our email: </em><a class="css-1g7m0tk" href="mailto:letters@nytimes.com" title=""><em class="css-2fg4z9 e1gzwzxm0">letters@nytimes.com</em></a><em class="css-2fg4z9 e1gzwzxm0">.</em></p>, <p class="css-jwz2nf etfikam0"><em class="css-2fg4z9 e1gzwzxm0">Follow The New York Times Opinion section on </em><a class="css-1g7m0tk" href="https://www.facebook.com/nytopinion" rel="noopener noreferrer" target="_blank" title=""><em class="css-2fg4z9 e1gzwzxm0">Facebook</em></a><em class="css-2fg4z9 e1gzwzxm0">, </em><a class="css-1g7m0tk" href="http://twitter.com/NYTOpinion" rel="noopener noreferrer" target="_blank" title=""><em class="css-2fg4z9 e1gzwzxm0">Twitter (@NYTopinion)</em></a><em class="css-2fg4z9 e1gzwzxm0"> and </em><a class="css-1g7m0tk" href="https://www.instagram.com/nytopinion/" rel="noopener noreferrer" target="_blank" title=""><em class="css-2fg4z9 e1gzwzxm0">Instagram</em></a><em class="css-2fg4z9 e1gzwzxm0">.</em></p>]]', 'link': '/2019/06/10/opinion/deepfake-pelosi-video.html', 'title': '<title data-rh="true">Opinion | Deepfakes Are Coming. We Can No Longer Believe What We See. - The New York Times</title>'}